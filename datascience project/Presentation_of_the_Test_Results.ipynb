{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5412bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a73e2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Requirement already satisfied: tabulate in c:\\\\users\\\\vasuk\\\\appdata\\\\local\\\\programs\\\\python\\\\python310\\\\lib\\\\site-packages (0.9.0)',\n",
       " '',\n",
       " '[notice] A new release of pip available: 22.3.1 -> 23.0.1',\n",
       " '[notice] To update, run: python.exe -m pip install --upgrade pip']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c78deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Load the trained Best Linear Regression model\n",
    "lr=pickle.load(open('Linear_class.sav', 'rb'))\n",
    "# load Logistic Regression model\n",
    "log = pickle.load(open('best_log.sav','rb'))\n",
    "#load the best knn model\n",
    "knn = pickle.load(open('knn_class.sav', 'rb'))\n",
    "#load Random fores model\n",
    "rf = pickle.load(open('RF_class.sav', 'rb'))\n",
    "#load Decision Trees model\n",
    "dt = pickle.load(open('Tree_class.sav','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57d3b2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "      <th>current_4</th>\n",
       "      <th>current_5</th>\n",
       "      <th>current_6</th>\n",
       "      <th>current_7</th>\n",
       "      <th>current_8</th>\n",
       "      <th>current_9</th>\n",
       "      <th>current_10</th>\n",
       "      <th>...</th>\n",
       "      <th>current_40</th>\n",
       "      <th>current_41</th>\n",
       "      <th>current_42</th>\n",
       "      <th>current_43</th>\n",
       "      <th>current_44</th>\n",
       "      <th>current_45</th>\n",
       "      <th>current_46</th>\n",
       "      <th>current_47</th>\n",
       "      <th>current_48</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.014600e-07</td>\n",
       "      <td>8.260300e-06</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.438600e-06</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63308</td>\n",
       "      <td>2.9646</td>\n",
       "      <td>8.1198</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.322600e-06</td>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.836600e-08</td>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63010</td>\n",
       "      <td>4.5155</td>\n",
       "      <td>9.5231</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_1     current_2  current_3  current_4     current_5  current_6  \\\n",
       "0 -3.014600e-07  8.260300e-06  -0.000012  -0.000002 -1.438600e-06  -0.000021   \n",
       "1  2.913200e-06 -5.247700e-06   0.000003  -0.000006  2.778900e-06  -0.000004   \n",
       "2 -2.951700e-06 -3.184000e-06  -0.000016  -0.000001 -1.575300e-06   0.000017   \n",
       "3 -1.322600e-06  8.820100e-06  -0.000016  -0.000005 -7.282900e-07   0.000004   \n",
       "4 -6.836600e-08  5.666300e-07  -0.000026  -0.000006 -7.940600e-07   0.000013   \n",
       "\n",
       "   current_7  current_8  current_9  current_10  ...  current_40  current_41  \\\n",
       "0   0.031718   0.031710   0.031721   -0.032963  ...    -0.63308      2.9646   \n",
       "1   0.030804   0.030810   0.030806   -0.033520  ...    -0.59314      7.6252   \n",
       "2   0.032877   0.032880   0.032896   -0.029834  ...    -0.63252      2.7784   \n",
       "3   0.029410   0.029401   0.029417   -0.030156  ...    -0.62289      6.5534   \n",
       "4   0.030119   0.030119   0.030145   -0.031393  ...    -0.63010      4.5155   \n",
       "\n",
       "   current_42  current_43  current_44  current_45  current_46  current_47  \\\n",
       "0      8.1198     -1.4961     -1.4961     -1.4961     -1.4996     -1.4996   \n",
       "1      6.1690     -1.4967     -1.4967     -1.4967     -1.5005     -1.5005   \n",
       "2      5.3017     -1.4983     -1.4983     -1.4982     -1.4985     -1.4985   \n",
       "3      6.2606     -1.4963     -1.4963     -1.4963     -1.4975     -1.4975   \n",
       "4      9.5231     -1.4958     -1.4958     -1.4958     -1.4959     -1.4959   \n",
       "\n",
       "   current_48  output  \n",
       "0     -1.4996       1  \n",
       "1     -1.5005       1  \n",
       "2     -1.4985       1  \n",
       "3     -1.4976       1  \n",
       "4     -1.4959       1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Group_9_data_cleaned.csv')\n",
    "# removing a redundant column\n",
    "df = df.drop(['Unnamed: 0'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97e6f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the data into differnt sets\n",
    "X = df.drop(['output'],axis=1)\n",
    "y = df['output']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=100)\n",
    "\n",
    "# Linear regression and KNN uses scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "model=scaler.fit(X)\n",
    "scaled_X=model.transform(X)\n",
    "scaled_X \n",
    "\n",
    "# Decision Trees and Random Forest does not need scaling \n",
    "x_train_scaled,x_test_scaled,y_train,y_test = train_test_split(scaled_X, y, test_size = 0.3, random_state=100)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.3, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebfe23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea043d9",
   "metadata": {},
   "source": [
    "## Linear Regression Testing data  Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d1e99b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for linear model is 0.02643422776733322\n",
      " The Recall_score for linear model is 0.024629673626160805\n",
      " The F1_score for linear model is 0.027335919534643875\n",
      " The roc auc score for linear model is 0.5322959052292122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros((x_test_scaled.shape[0], len(lr)))\n",
    "for i, model in enumerate(lr):\n",
    "    predictions[:, i] = model.predict(x_test_scaled)\n",
    "# assign class based on highest prediction score\n",
    "y_test_pred = np.argmax(predictions, axis=1)    \n",
    "\n",
    "# Roc auc score \n",
    "test_predictions = np.zeros((x_test_scaled.shape[0], len(lr)))\n",
    "for i, model in enumerate(lr):\n",
    "    test_predictions[:, i] = model.predict(x_test_scaled)\n",
    "test_roc_auc_scores = []\n",
    "for c in np.unique(y):\n",
    "    y_binary_test = (y_test == c).astype(int)\n",
    "    if c <= i:\n",
    "       y_pred = test_predictions[:, c]\n",
    "       roc_auc = roc_auc_score(y_binary_test, y_pred)\n",
    "       test_roc_auc_scores.append(roc_auc)\n",
    "test_avg_roc_auc_score = np.mean(test_roc_auc_scores)\n",
    "\n",
    "print(f\" The accuracy for linear model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "print(f\" The Recall_score for linear model is {recall_score(y_test,y_test_pred,average = 'macro')}\")\n",
    "print(f\" The F1_score for linear model is {f1_score(y_test,y_test_pred,average = 'weighted')}\")\n",
    "print(f\" The roc auc score for linear model is {test_avg_roc_auc_score}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2e1ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [1553    0    0    0    0   47    0    1    3    0    0    0]\n",
      " [   0  827    3    2    0    8    0    0    4  554  287    0]\n",
      " [  56   98  237  218   43   40  626   19   10  192    2    0]\n",
      " [   0    9    2  980    9    0  493    2    3   63    0    0]\n",
      " [  45    1    5  276  504   10  334  259   82    8    2    0]\n",
      " [1141    6    0    0    2  456    0    9   31    0    6    0]\n",
      " [   0    0    0   21    0    0 1567    0    0    2    0    0]\n",
      " [ 318    2    1  111  137   14   52  805  144    0    1    0]\n",
      " [ 494    6    0    2    4   56    0   50  936    8   12    0]\n",
      " [   0  179    2    2    0    0    1    0    0 1379   72    0]\n",
      " [   0    9    0    0    0    0    0    0    8   20 1570    0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for linear model of test data\n",
    "print(confusion_matrix(y_test,y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report for linear model of test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f8f88c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00      1604\n",
      "           2       0.01      0.00      0.00      1685\n",
      "           3       0.14      0.14      0.14      1541\n",
      "           4       0.01      0.01      0.01      1561\n",
      "           5       0.02      0.01      0.01      1526\n",
      "           6       0.00      0.00      0.00      1651\n",
      "           7       0.00      0.00      0.00      1590\n",
      "           8       0.12      0.09      0.10      1585\n",
      "           9       0.00      0.01      0.00      1568\n",
      "          10       0.04      0.04      0.04      1635\n",
      "          11       0.00      0.00      0.00      1607\n",
      "\n",
      "    accuracy                           0.03     17553\n",
      "   macro avg       0.03      0.02      0.03     17553\n",
      "weighted avg       0.03      0.03      0.03     17553\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f38b6a",
   "metadata": {},
   "source": [
    "## Logistic Regression Test data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a62b4d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for knn model is 0.9054292713496268\n",
      " The Recall_score for knn model is 0.9054255304241362\n",
      " The F1_score for knn model is 0.9048152927309002\n",
      " The roc auc score for knn model is 0.9943484272756621\n"
     ]
    }
   ],
   "source": [
    "y_test_log = log.predict(x_test_scaled)\n",
    "y_test_prob_log = log.predict_proba(x_test_scaled)\n",
    "print(f\" The accuracy for knn model is {accuracy_score(y_test,y_test_log)}\")\n",
    "print(f\" The Recall_score for knn model is {recall_score(y_test,y_test_log,average = 'macro')}\")\n",
    "print(f\" The F1_score for knn model is {f1_score(y_test,y_test_log,average = 'weighted')}\")\n",
    "print(f\" The roc auc score for knn model is {roc_auc_score(y_test,y_test_prob_log,average='weighted',multi_class='ovr')}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5961f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [1553    0    0    0    0   47    0    1    3    0    0    0]\n",
      " [   0  827    3    2    0    8    0    0    4  554  287    0]\n",
      " [  56   98  237  218   43   40  626   19   10  192    2    0]\n",
      " [   0    9    2  980    9    0  493    2    3   63    0    0]\n",
      " [  45    1    5  276  504   10  334  259   82    8    2    0]\n",
      " [1141    6    0    0    2  456    0    9   31    0    6    0]\n",
      " [   0    0    0   21    0    0 1567    0    0    2    0    0]\n",
      " [ 318    2    1  111  137   14   52  805  144    0    1    0]\n",
      " [ 494    6    0    2    4   56    0   50  936    8   12    0]\n",
      " [   0  179    2    2    0    0    1    0    0 1379   72    0]\n",
      " [   0    9    0    0    0    0    0    0    8   20 1570    0]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix of test data\n",
    "print(confusion_matrix(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ebbece6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00      1604\n",
      "           2       0.01      0.00      0.00      1685\n",
      "           3       0.14      0.14      0.14      1541\n",
      "           4       0.01      0.01      0.01      1561\n",
      "           5       0.02      0.01      0.01      1526\n",
      "           6       0.00      0.00      0.00      1651\n",
      "           7       0.00      0.00      0.00      1590\n",
      "           8       0.12      0.09      0.10      1585\n",
      "           9       0.00      0.01      0.00      1568\n",
      "          10       0.04      0.04      0.04      1635\n",
      "          11       0.00      0.00      0.00      1607\n",
      "\n",
      "    accuracy                           0.03     17553\n",
      "   macro avg       0.03      0.02      0.03     17553\n",
      "weighted avg       0.03      0.03      0.03     17553\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print classification report of test data\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28002c",
   "metadata": {},
   "source": [
    "## KNN classification Test data results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b37b7c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for knn model is 0.9754457927419814\n",
      " The Recall_score for knn model is 0.975715100175092\n",
      " The F1_score for knn model is 0.9754475439861401\n",
      " The roc auc score for knn model is 0.9994078439670819\n"
     ]
    }
   ],
   "source": [
    "y_test_knn = knn.predict(x_test_scaled)\n",
    "y_test_prob_knn = knn.predict_proba(x_test_scaled)\n",
    "print(f\" The accuracy for knn model is {accuracy_score(y_test,y_test_knn)}\")\n",
    "print(f\" The Recall_score for knn model is {recall_score(y_test,y_test_knn,average = 'macro')}\")\n",
    "print(f\" The F1_score for knn model is {f1_score(y_test,y_test_knn,average = 'weighted')}\")\n",
    "print(f\" The roc auc score for knn model is {roc_auc_score(y_test,y_test_prob_knn,average='weighted',multi_class='ovr')}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bf458f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1538    0    2    0    0   64    0    0    0    0    0]\n",
      " [   1 1614    0    0    0    6    0    0    3   61    0]\n",
      " [   0    0 1539    0    0    2    0    0    0    0    0]\n",
      " [   0    0    0 1545   15    0    0    1    0    0    0]\n",
      " [   1    0    2   13 1478    0    0   32    0    0    0]\n",
      " [  42    4    0    0    3 1599    0    1    2    0    0]\n",
      " [   0    0    0    0    0    0 1590    0    0    0    0]\n",
      " [   0    0    0   28   28    2    0 1525    2    0    0]\n",
      " [   2    1    0    1    4    8    0    5 1547    0    0]\n",
      " [   0   92    0    0    0    3    0    0    0 1540    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1607]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for the test data\n",
    "print(confusion_matrix(y_test,y_test_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2e9c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.96      0.96      1604\n",
      "           2       0.94      0.96      0.95      1685\n",
      "           3       1.00      1.00      1.00      1541\n",
      "           4       0.97      0.99      0.98      1561\n",
      "           5       0.97      0.97      0.97      1526\n",
      "           6       0.95      0.97      0.96      1651\n",
      "           7       1.00      1.00      1.00      1590\n",
      "           8       0.98      0.96      0.97      1585\n",
      "           9       1.00      0.99      0.99      1568\n",
      "          10       0.96      0.94      0.95      1635\n",
      "          11       1.00      1.00      1.00      1607\n",
      "\n",
      "    accuracy                           0.98     17553\n",
      "   macro avg       0.98      0.98      0.98     17553\n",
      "weighted avg       0.98      0.98      0.98     17553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for the test data\n",
    "print(classification_report(y_test,y_test_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9f794",
   "metadata": {},
   "source": [
    "## Random Forests test data results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "136b355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for random forests model is 0.9904289864980346\n",
      " The Recall_score for random forests model is 0.9903294228469653\n",
      " The F1_score for random forests model is 0.9904325023867102\n",
      " The roc auc score for random forests model is 0.999919685674305\n"
     ]
    }
   ],
   "source": [
    "y_test_rf = rf.predict(X_test)\n",
    "y_test_prob_rf = rf.predict_proba(X_test)\n",
    "print(f\" The accuracy for random forests model is {accuracy_score(y_test,y_test_rf)}\")\n",
    "print(f\" The Recall_score for random forests model is {recall_score(y_test,y_test_rf,average = 'macro')}\")\n",
    "print(f\" The F1_score for random forests model is {f1_score(y_test,y_test_rf,average = 'weighted')}\")\n",
    "print(f\" The roc auc score for random forests model is {roc_auc_score(y_test,y_test_prob_rf,average='weighted',multi_class='ovr')}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f3af458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1592    0    0    0    0   12    0    0    0    0    0]\n",
      " [   0 1671    1    0    0    0    0    0    0   12    1]\n",
      " [   0    0 1521    0   20    0    0    0    0    0    0]\n",
      " [   0    0    4 1555    2    0    0    0    0    0    0]\n",
      " [   0    0   10    2 1480    0    0   34    0    0    0]\n",
      " [  15    0    0    0    0 1630    0    0    6    0    0]\n",
      " [   0    0    0    0    0    0 1590    0    0    0    0]\n",
      " [   0    0    0    4   28    0    0 1553    0    0    0]\n",
      " [   0    2    0    0    0    5    0    2 1556    3    0]\n",
      " [   0    4    0    0    0    1    0    0    0 1630    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1607]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for random forests model\n",
    "print(confusion_matrix(y_test,y_test_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31142f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99      1604\n",
      "           2       1.00      0.99      0.99      1685\n",
      "           3       0.99      0.99      0.99      1541\n",
      "           4       1.00      1.00      1.00      1561\n",
      "           5       0.97      0.97      0.97      1526\n",
      "           6       0.99      0.99      0.99      1651\n",
      "           7       1.00      1.00      1.00      1590\n",
      "           8       0.98      0.98      0.98      1585\n",
      "           9       1.00      0.99      0.99      1568\n",
      "          10       0.99      1.00      0.99      1635\n",
      "          11       1.00      1.00      1.00      1607\n",
      "\n",
      "    accuracy                           0.99     17553\n",
      "   macro avg       0.99      0.99      0.99     17553\n",
      "weighted avg       0.99      0.99      0.99     17553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for random forests model\n",
    "print(classification_report(y_test,y_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6acf8e",
   "metadata": {},
   "source": [
    "## Decision Trees test data results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4a73104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for decision trees model is 0.9741924457357717\n",
      " The Recall_score for decision trees model is 0.973981783438544\n",
      " The F1_score for decision trees model is 0.9742507800604092\n",
      " The roc auc score for decision trees model is 0.9970749762738759\n"
     ]
    }
   ],
   "source": [
    "y_test_dt = dt.predict(X_test)\n",
    "y_test_prob_dt = dt.predict_proba(X_test)\n",
    "print(f\" The accuracy for decision trees model is {accuracy_score(y_test,y_test_dt)}\")\n",
    "print(f\" The Recall_score for decision trees model is {recall_score(y_test,y_test_dt,average = 'macro')}\")\n",
    "print(f\" The F1_score for decision trees model is {f1_score(y_test,y_test_dt,average = 'weighted')}\")\n",
    "print(f\" The roc auc score for decision trees model is {roc_auc_score(y_test,y_test_prob_dt,average='weighted',multi_class='ovr')}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f4948085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1555    0    0    0    0   46    0    0    3    0    0]\n",
      " [   0 1656    0    0    1    0    0    0    2   25    1]\n",
      " [   0    0 1504    0   37    0    0    0    0    0    0]\n",
      " [   0    0   23 1534    4    0    0    0    0    0    0]\n",
      " [   0    0   20    3 1425    0    0   78    0    0    0]\n",
      " [  14    0    0    0    0 1597    0    0   40    0    0]\n",
      " [   0    2    0    0    0    0 1588    0    0    0    0]\n",
      " [   0    0    1    2   93    0    0 1489    0    0    0]\n",
      " [   1    2    1    0    0   28    0    2 1532    2    0]\n",
      " [   0   21    0    0    0    0    0    0    1 1613    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1607]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for decision trees model for test data\n",
    "print(confusion_matrix(y_test,y_test_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cae6400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.97      0.98      1604\n",
      "           2       0.99      0.98      0.98      1685\n",
      "           3       0.97      0.98      0.97      1541\n",
      "           4       1.00      0.98      0.99      1561\n",
      "           5       0.91      0.93      0.92      1526\n",
      "           6       0.96      0.97      0.96      1651\n",
      "           7       1.00      1.00      1.00      1590\n",
      "           8       0.95      0.94      0.94      1585\n",
      "           9       0.97      0.98      0.97      1568\n",
      "          10       0.98      0.99      0.99      1635\n",
      "          11       1.00      1.00      1.00      1607\n",
      "\n",
      "    accuracy                           0.97     17553\n",
      "   macro avg       0.97      0.97      0.97     17553\n",
      "weighted avg       0.97      0.97      0.97     17553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for decision trees model for test data\n",
    "print(classification_report(y_test,y_test_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc127b",
   "metadata": {},
   "source": [
    "# Base line model - Most frequent  strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff586a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most frequent occuring  strategy always predicts the most frequent class in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd584d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "# Train the classifier on the training set\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_test_base = dummy_clf.predict(X_test)\n",
    "# predict prob on test set\n",
    "y_proba = dummy_clf.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6349b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for baseline model is 0.08693670597618641\n",
      " The Recall_score for baseline model is 0.09090909090909091\n",
      " The F1_score for baseline model is 0.013906956687421819\n",
      " The roc auc score for baseline model is 0.5\n"
     ]
    }
   ],
   "source": [
    "print(f\" The accuracy for baseline model is {accuracy_score(y_test,y_test_base)}\")\n",
    "print(f\" The Recall_score for baseline model is {recall_score(y_test,y_test_base,average = 'macro')}\")\n",
    "print(f\" The F1_score for baseline model is {f1_score(y_test,y_test_base,average = 'weighted')}\")\n",
    "print(f\" The roc auc score for baseline model is {roc_auc_score(y_test,y_proba,average='weighted',multi_class='ovr')}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b5da05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 1604    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1685    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1541    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1561    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1526    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1651    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1590    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1585    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1568    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1635    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1607    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for base model\n",
    "print(confusion_matrix(y_test,y_test_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a20eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00      1604\n",
      "           2       0.00      0.00      0.00      1685\n",
      "           3       0.00      0.00      0.00      1541\n",
      "           4       0.00      0.00      0.00      1561\n",
      "           5       0.09      1.00      0.16      1526\n",
      "           6       0.00      0.00      0.00      1651\n",
      "           7       0.00      0.00      0.00      1590\n",
      "           8       0.00      0.00      0.00      1585\n",
      "           9       0.00      0.00      0.00      1568\n",
      "          10       0.00      0.00      0.00      1635\n",
      "          11       0.00      0.00      0.00      1607\n",
      "\n",
      "    accuracy                           0.09     17553\n",
      "   macro avg       0.01      0.09      0.01     17553\n",
      "weighted avg       0.01      0.09      0.01     17553\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# classification report for base model\n",
    "print(classification_report(y_test,y_test_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f1393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02f9d452",
   "metadata": {},
   "source": [
    "# Base line model - stratified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stratified strategy predicts class probabilities based on the class distribution in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4ee62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "# Train the classifier on the training set\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_test_str = dummy_clf.predict(X_test)\n",
    "# predict prob on test set\n",
    "y_proba_str = dummy_clf.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51e4c471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for baseline model is 0.09149433145331283\n",
      " The Recall_score for baseline model is 0.09148552752183532\n",
      " The F1_score for baseline model is 0.09146205327993441\n",
      " The roc auc score for baseline model is 0.5000131020735387\n"
     ]
    }
   ],
   "source": [
    "print(f\" The accuracy for baseline model is {accuracy_score(y_test,y_test_str)}\")\n",
    "print(f\" The Recall_score for baseline model is {recall_score(y_test,y_test_str,average = 'macro')}\")\n",
    "print(f\" The F1_score for baseline model is {f1_score(y_test,y_test_str,average = 'weighted')}\")\n",
    "print(f\" The roc auc score for baseline model is {roc_auc_score(y_test,y_proba_str,average='weighted',multi_class='ovr')}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be27e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136 138 176 140 148 141 157 138 147 137 146]\n",
      " [157 178 139 163 158 158 158 131 157 146 140]\n",
      " [135 135 147 140 144 118 137 140 130 149 166]\n",
      " [147 148 134 126 137 122 146 142 147 146 166]\n",
      " [142 139 140 142 153 153 140 135 120 138 124]\n",
      " [138 144 157 162 162 139 158 146 155 155 135]\n",
      " [154 128 139 130 156 140 167 140 165 143 128]\n",
      " [126 168 133 144 157 157 136 141 143 137 143]\n",
      " [125 151 147 128 146 154 128 170 141 138 140]\n",
      " [160 151 144 154 136 145 140 170 131 146 158]\n",
      " [136 165 130 146 174 139 143 142 148 152 132]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for stratified model\n",
    "print(confusion_matrix(y_test,y_test_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e1ac39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.08      0.09      1604\n",
      "           2       0.11      0.11      0.11      1685\n",
      "           3       0.09      0.10      0.09      1541\n",
      "           4       0.08      0.08      0.08      1561\n",
      "           5       0.09      0.10      0.10      1526\n",
      "           6       0.09      0.08      0.09      1651\n",
      "           7       0.10      0.11      0.10      1590\n",
      "           8       0.09      0.09      0.09      1585\n",
      "           9       0.09      0.09      0.09      1568\n",
      "          10       0.09      0.09      0.09      1635\n",
      "          11       0.08      0.08      0.08      1607\n",
      "\n",
      "    accuracy                           0.09     17553\n",
      "   macro avg       0.09      0.09      0.09     17553\n",
      "weighted avg       0.09      0.09      0.09     17553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for stratified model\n",
    "print(classification_report(y_test,y_test_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca1c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

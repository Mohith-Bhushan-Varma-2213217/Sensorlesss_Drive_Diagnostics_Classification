{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17c34c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1fc7523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "      <th>current_4</th>\n",
       "      <th>current_5</th>\n",
       "      <th>current_6</th>\n",
       "      <th>current_7</th>\n",
       "      <th>current_8</th>\n",
       "      <th>current_9</th>\n",
       "      <th>current_10</th>\n",
       "      <th>...</th>\n",
       "      <th>current_40</th>\n",
       "      <th>current_41</th>\n",
       "      <th>current_42</th>\n",
       "      <th>current_43</th>\n",
       "      <th>current_44</th>\n",
       "      <th>current_45</th>\n",
       "      <th>current_46</th>\n",
       "      <th>current_47</th>\n",
       "      <th>current_48</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.014600e-07</td>\n",
       "      <td>8.260300e-06</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.438600e-06</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63308</td>\n",
       "      <td>2.9646</td>\n",
       "      <td>8.1198</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.322600e-06</td>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.836600e-08</td>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63010</td>\n",
       "      <td>4.5155</td>\n",
       "      <td>9.5231</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_1     current_2  current_3  current_4     current_5  current_6  \\\n",
       "0 -3.014600e-07  8.260300e-06  -0.000012  -0.000002 -1.438600e-06  -0.000021   \n",
       "1  2.913200e-06 -5.247700e-06   0.000003  -0.000006  2.778900e-06  -0.000004   \n",
       "2 -2.951700e-06 -3.184000e-06  -0.000016  -0.000001 -1.575300e-06   0.000017   \n",
       "3 -1.322600e-06  8.820100e-06  -0.000016  -0.000005 -7.282900e-07   0.000004   \n",
       "4 -6.836600e-08  5.666300e-07  -0.000026  -0.000006 -7.940600e-07   0.000013   \n",
       "\n",
       "   current_7  current_8  current_9  current_10  ...  current_40  current_41  \\\n",
       "0   0.031718   0.031710   0.031721   -0.032963  ...    -0.63308      2.9646   \n",
       "1   0.030804   0.030810   0.030806   -0.033520  ...    -0.59314      7.6252   \n",
       "2   0.032877   0.032880   0.032896   -0.029834  ...    -0.63252      2.7784   \n",
       "3   0.029410   0.029401   0.029417   -0.030156  ...    -0.62289      6.5534   \n",
       "4   0.030119   0.030119   0.030145   -0.031393  ...    -0.63010      4.5155   \n",
       "\n",
       "   current_42  current_43  current_44  current_45  current_46  current_47  \\\n",
       "0      8.1198     -1.4961     -1.4961     -1.4961     -1.4996     -1.4996   \n",
       "1      6.1690     -1.4967     -1.4967     -1.4967     -1.5005     -1.5005   \n",
       "2      5.3017     -1.4983     -1.4983     -1.4982     -1.4985     -1.4985   \n",
       "3      6.2606     -1.4963     -1.4963     -1.4963     -1.4975     -1.4975   \n",
       "4      9.5231     -1.4958     -1.4958     -1.4958     -1.4959     -1.4959   \n",
       "\n",
       "   current_48  output  \n",
       "0     -1.4996       1  \n",
       "1     -1.5005       1  \n",
       "2     -1.4985       1  \n",
       "3     -1.4976       1  \n",
       "4     -1.4959       1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Group_9_data_cleaned.csv')\n",
    "data.head(3)\n",
    "# removing a redundant column\n",
    "df = data.drop(['Unnamed: 0'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f43d5026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58509, 49)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of the data \n",
    "# The data has 58509 rows \n",
    "# The data has 49 features \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2db6d1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "      <th>current_4</th>\n",
       "      <th>current_5</th>\n",
       "      <th>current_6</th>\n",
       "      <th>current_7</th>\n",
       "      <th>current_8</th>\n",
       "      <th>current_9</th>\n",
       "      <th>current_10</th>\n",
       "      <th>...</th>\n",
       "      <th>current_40</th>\n",
       "      <th>current_41</th>\n",
       "      <th>current_42</th>\n",
       "      <th>current_43</th>\n",
       "      <th>current_44</th>\n",
       "      <th>current_45</th>\n",
       "      <th>current_46</th>\n",
       "      <th>current_47</th>\n",
       "      <th>current_48</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58509.000000</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.756436e-06</td>\n",
       "      <td>1.111802e-06</td>\n",
       "      <td>-9.722586e-07</td>\n",
       "      <td>1.775487e-06</td>\n",
       "      <td>-7.457535e-07</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.006349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.650427</td>\n",
       "      <td>5.730645</td>\n",
       "      <td>7.702923</td>\n",
       "      <td>-1.500891</td>\n",
       "      <td>-1.500915</td>\n",
       "      <td>-1.500809</td>\n",
       "      <td>-1.497787</td>\n",
       "      <td>-1.497814</td>\n",
       "      <td>-1.497710</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.199783e-05</td>\n",
       "      <td>1.520782e-04</td>\n",
       "      <td>7.956279e-06</td>\n",
       "      <td>3.234750e-05</td>\n",
       "      <td>1.490893e-04</td>\n",
       "      <td>0.033692</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.033701</td>\n",
       "      <td>0.050735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100670</td>\n",
       "      <td>5.781169</td>\n",
       "      <td>4.347205</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>3.162305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-6.427550e-05</td>\n",
       "      <td>-2.937900e-04</td>\n",
       "      <td>-1.887580e-05</td>\n",
       "      <td>-6.547550e-05</td>\n",
       "      <td>-2.915565e-04</td>\n",
       "      <td>-0.086972</td>\n",
       "      <td>-0.087041</td>\n",
       "      <td>-0.086978</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902350</td>\n",
       "      <td>-0.596830</td>\n",
       "      <td>0.320660</td>\n",
       "      <td>-1.510950</td>\n",
       "      <td>-1.511200</td>\n",
       "      <td>-1.510700</td>\n",
       "      <td>-1.504700</td>\n",
       "      <td>-1.504550</td>\n",
       "      <td>-1.504450</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-1.444400e-05</td>\n",
       "      <td>-7.239600e-05</td>\n",
       "      <td>-5.417500e-06</td>\n",
       "      <td>-1.475300e-05</td>\n",
       "      <td>-7.379100e-05</td>\n",
       "      <td>-0.019927</td>\n",
       "      <td>-0.019951</td>\n",
       "      <td>-0.019925</td>\n",
       "      <td>-0.032144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715470</td>\n",
       "      <td>1.450300</td>\n",
       "      <td>4.436300</td>\n",
       "      <td>-1.503300</td>\n",
       "      <td>-1.503400</td>\n",
       "      <td>-1.503200</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>8.804600e-07</td>\n",
       "      <td>5.137700e-07</td>\n",
       "      <td>-1.059100e-06</td>\n",
       "      <td>7.540200e-07</td>\n",
       "      <td>-1.659300e-07</td>\n",
       "      <td>0.013226</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>-0.015566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.661710</td>\n",
       "      <td>3.301300</td>\n",
       "      <td>6.479100</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.877700e-05</td>\n",
       "      <td>7.520000e-05</td>\n",
       "      <td>3.554700e-06</td>\n",
       "      <td>1.906200e-05</td>\n",
       "      <td>7.138600e-05</td>\n",
       "      <td>0.024770</td>\n",
       "      <td>0.024776</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.020614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573980</td>\n",
       "      <td>8.288500</td>\n",
       "      <td>9.857500</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.496200</td>\n",
       "      <td>-1.496300</td>\n",
       "      <td>-1.496200</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>6.860850e-05</td>\n",
       "      <td>2.965940e-04</td>\n",
       "      <td>1.701300e-05</td>\n",
       "      <td>6.978450e-05</td>\n",
       "      <td>2.891515e-04</td>\n",
       "      <td>0.069125</td>\n",
       "      <td>0.069130</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>0.099751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361745</td>\n",
       "      <td>18.545800</td>\n",
       "      <td>17.989300</td>\n",
       "      <td>-1.490550</td>\n",
       "      <td>-1.490400</td>\n",
       "      <td>-1.490700</td>\n",
       "      <td>-1.491100</td>\n",
       "      <td>-1.491350</td>\n",
       "      <td>-1.491250</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          current_1     current_2     current_3     current_4     current_5  \\\n",
       "count  58509.000000  5.850900e+04  5.850900e+04  5.850900e+04  5.850900e+04   \n",
       "mean      -0.000003  1.756436e-06  1.111802e-06 -9.722586e-07  1.775487e-06   \n",
       "std        0.000008  3.199783e-05  1.520782e-04  7.956279e-06  3.234750e-05   \n",
       "min       -0.000021 -6.427550e-05 -2.937900e-04 -1.887580e-05 -6.547550e-05   \n",
       "25%       -0.000007 -1.444400e-05 -7.239600e-05 -5.417500e-06 -1.475300e-05   \n",
       "50%       -0.000003  8.804600e-07  5.137700e-07 -1.059100e-06  7.540200e-07   \n",
       "75%        0.000002  1.877700e-05  7.520000e-05  3.554700e-06  1.906200e-05   \n",
       "max        0.000015  6.860850e-05  2.965940e-04  1.701300e-05  6.978450e-05   \n",
       "\n",
       "          current_6     current_7     current_8     current_9    current_10  \\\n",
       "count  5.850900e+04  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean  -7.457535e-07      0.002854      0.002849      0.002849     -0.006349   \n",
       "std    1.490893e-04      0.033692      0.033700      0.033701      0.050735   \n",
       "min   -2.915565e-04     -0.086972     -0.087041     -0.086978     -0.111281   \n",
       "25%   -7.379100e-05     -0.019927     -0.019951     -0.019925     -0.032144   \n",
       "50%   -1.659300e-07      0.013226      0.013230      0.013247     -0.015566   \n",
       "75%    7.138600e-05      0.024770      0.024776      0.024777      0.020614   \n",
       "max    2.891515e-04      0.069125      0.069130      0.069131      0.099751   \n",
       "\n",
       "       ...    current_40    current_41    current_42    current_43  \\\n",
       "count  ...  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean   ...     -0.650427      5.730645      7.702923     -1.500891   \n",
       "std    ...      0.100670      5.781169      4.347205      0.003629   \n",
       "min    ...     -0.902350     -0.596830      0.320660     -1.510950   \n",
       "25%    ...     -0.715470      1.450300      4.436300     -1.503300   \n",
       "50%    ...     -0.661710      3.301300      6.479100     -1.500300   \n",
       "75%    ...     -0.573980      8.288500      9.857500     -1.498200   \n",
       "max    ...     -0.361745     18.545800     17.989300     -1.490550   \n",
       "\n",
       "         current_44    current_45    current_46    current_47    current_48  \\\n",
       "count  58509.000000  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean      -1.500915     -1.500809     -1.497787     -1.497814     -1.497710   \n",
       "std        0.003640      0.003600      0.003002      0.002984      0.002988   \n",
       "min       -1.511200     -1.510700     -1.504700     -1.504550     -1.504450   \n",
       "25%       -1.503400     -1.503200     -1.499600     -1.499600     -1.499500   \n",
       "50%       -1.500300     -1.500300     -1.498100     -1.498100     -1.498000   \n",
       "75%       -1.498200     -1.498200     -1.496200     -1.496300     -1.496200   \n",
       "max       -1.490400     -1.490700     -1.491100     -1.491350     -1.491250   \n",
       "\n",
       "             output  \n",
       "count  58509.000000  \n",
       "mean       6.000000  \n",
       "std        3.162305  \n",
       "min        1.000000  \n",
       "25%        3.000000  \n",
       "50%        6.000000  \n",
       "75%        9.000000  \n",
       "max       11.000000  \n",
       "\n",
       "[8 rows x 49 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of the data \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5e7aec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 11 different classes in the output data \n",
    "# which are from 1 to 11 classes \n",
    "df['output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60c38c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     5319\n",
       "2     5319\n",
       "3     5319\n",
       "4     5319\n",
       "5     5319\n",
       "6     5319\n",
       "7     5319\n",
       "8     5319\n",
       "9     5319\n",
       "10    5319\n",
       "11    5319\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the number of each output class labels \n",
    "# It is a blanced multi class dataset with each class is having equal number of output labels \n",
    "df['output'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a1f85",
   "metadata": {},
   "source": [
    "# first variable selection using lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53a19cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_2\n",
      "current_4\n",
      "current_5\n",
      "current_7\n",
      "current_8\n",
      "current_10\n",
      "current_12\n",
      "current_19\n",
      "current_20\n",
      "current_21\n",
      "current_25\n",
      "current_28\n",
      "current_33\n",
      "current_34\n",
      "current_35\n",
      "current_37\n",
      "current_44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "# Dividing input and output labels\n",
    "X = df.drop(['output'],axis=1)\n",
    "y = df['output']\n",
    "\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create Lasso object\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit Lasso\n",
    "lasso.fit(X_scaled, y)\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "# Print selected features\n",
    "selected_features = []\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    if coef != 0:\n",
    "        print(feature)\n",
    "        selected_features.append(feature)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "27acf7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['current_2', 'current_4', 'current_5', 'current_7', 'current_8', 'current_10', 'current_12', 'current_19', 'current_20', 'current_21', 'current_25', 'current_28', 'current_33', 'current_34', 'current_35', 'current_37', 'current_44']\n"
     ]
    }
   ],
   "source": [
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f61bce8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_4</th>\n",
       "      <th>current_5</th>\n",
       "      <th>current_7</th>\n",
       "      <th>current_8</th>\n",
       "      <th>current_10</th>\n",
       "      <th>current_12</th>\n",
       "      <th>current_19</th>\n",
       "      <th>current_20</th>\n",
       "      <th>current_21</th>\n",
       "      <th>current_25</th>\n",
       "      <th>current_28</th>\n",
       "      <th>current_33</th>\n",
       "      <th>current_34</th>\n",
       "      <th>current_35</th>\n",
       "      <th>current_37</th>\n",
       "      <th>current_44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.260300e-06</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.438600e-06</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>-0.032941</td>\n",
       "      <td>0.89669</td>\n",
       "      <td>0.89669</td>\n",
       "      <td>0.89669</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>-0.001248</td>\n",
       "      <td>-0.004378</td>\n",
       "      <td>-0.004384</td>\n",
       "      <td>-0.66732</td>\n",
       "      <td>-1.4961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>-0.033519</td>\n",
       "      <td>0.89583</td>\n",
       "      <td>0.89583</td>\n",
       "      <td>0.89580</td>\n",
       "      <td>-0.009402</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>-0.001342</td>\n",
       "      <td>-0.65404</td>\n",
       "      <td>-1.4967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>-0.029849</td>\n",
       "      <td>0.89583</td>\n",
       "      <td>0.89583</td>\n",
       "      <td>0.89581</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>-0.67146</td>\n",
       "      <td>-1.4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>-0.030159</td>\n",
       "      <td>0.89480</td>\n",
       "      <td>0.89481</td>\n",
       "      <td>0.89479</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>-0.004974</td>\n",
       "      <td>-0.004966</td>\n",
       "      <td>-0.67766</td>\n",
       "      <td>-1.4963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>-0.031405</td>\n",
       "      <td>0.89656</td>\n",
       "      <td>0.89656</td>\n",
       "      <td>0.89655</td>\n",
       "      <td>-0.000860</td>\n",
       "      <td>0.005616</td>\n",
       "      <td>-0.003800</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>-0.004646</td>\n",
       "      <td>-0.65867</td>\n",
       "      <td>-1.4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58504</th>\n",
       "      <td>1.854900e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-5.910200e-06</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>-0.083419</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>-0.111323</td>\n",
       "      <td>2.29100</td>\n",
       "      <td>2.29090</td>\n",
       "      <td>2.29060</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>-0.008362</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>-0.41812</td>\n",
       "      <td>-1.5025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58505</th>\n",
       "      <td>1.983500e-05</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-6.547550e-05</td>\n",
       "      <td>-0.085131</td>\n",
       "      <td>-0.085151</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>-0.111323</td>\n",
       "      <td>2.29210</td>\n",
       "      <td>2.29200</td>\n",
       "      <td>2.29110</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>-0.009709</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.42137</td>\n",
       "      <td>-1.5025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58506</th>\n",
       "      <td>1.859400e-05</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>3.827500e-06</td>\n",
       "      <td>-0.081989</td>\n",
       "      <td>-0.082008</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>-0.111323</td>\n",
       "      <td>2.29070</td>\n",
       "      <td>2.29070</td>\n",
       "      <td>2.28960</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.008709</td>\n",
       "      <td>-0.008109</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>-0.39929</td>\n",
       "      <td>-1.5035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58507</th>\n",
       "      <td>3.396900e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>6.500800e-06</td>\n",
       "      <td>-0.081500</td>\n",
       "      <td>-0.081534</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>-0.111323</td>\n",
       "      <td>2.29050</td>\n",
       "      <td>2.29040</td>\n",
       "      <td>2.28980</td>\n",
       "      <td>0.019670</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>-0.010470</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.43276</td>\n",
       "      <td>-1.5029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58508</th>\n",
       "      <td>5.225900e-05</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.795600e-06</td>\n",
       "      <td>-0.083034</td>\n",
       "      <td>-0.083086</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>-0.111323</td>\n",
       "      <td>2.29300</td>\n",
       "      <td>2.29290</td>\n",
       "      <td>2.29220</td>\n",
       "      <td>0.029245</td>\n",
       "      <td>-0.010920</td>\n",
       "      <td>-0.010627</td>\n",
       "      <td>-0.001158</td>\n",
       "      <td>-0.001167</td>\n",
       "      <td>-0.43513</td>\n",
       "      <td>-1.5040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58509 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          current_2  current_4     current_5  current_7  current_8  \\\n",
       "0      8.260300e-06  -0.000002 -1.438600e-06   0.031718   0.031710   \n",
       "1     -5.247700e-06  -0.000006  2.778900e-06   0.030804   0.030810   \n",
       "2     -3.184000e-06  -0.000001 -1.575300e-06   0.032877   0.032880   \n",
       "3      8.820100e-06  -0.000005 -7.282900e-07   0.029410   0.029401   \n",
       "4      5.666300e-07  -0.000006 -7.940600e-07   0.030119   0.030119   \n",
       "...             ...        ...           ...        ...        ...   \n",
       "58504  1.854900e-06   0.000017 -5.910200e-06  -0.083417  -0.083419   \n",
       "58505  1.983500e-05  -0.000018 -6.547550e-05  -0.085131  -0.085151   \n",
       "58506  1.859400e-05  -0.000003  3.827500e-06  -0.081989  -0.082008   \n",
       "58507  3.396900e-05   0.000005  6.500800e-06  -0.081500  -0.081534   \n",
       "58508  5.225900e-05   0.000010  3.795600e-06  -0.083034  -0.083086   \n",
       "\n",
       "       current_10  current_12  current_19  current_20  current_21  current_25  \\\n",
       "0       -0.032963   -0.032941     0.89669     0.89669     0.89669    0.007680   \n",
       "1       -0.033520   -0.033519     0.89583     0.89583     0.89580   -0.009402   \n",
       "2       -0.029834   -0.029849     0.89583     0.89583     0.89581    0.005951   \n",
       "3       -0.030156   -0.030159     0.89480     0.89481     0.89479    0.002056   \n",
       "4       -0.031393   -0.031405     0.89656     0.89656     0.89655   -0.000860   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "58504   -0.111281   -0.111323     2.29100     2.29090     2.29060    0.023419   \n",
       "58505   -0.111281   -0.111323     2.29210     2.29200     2.29110    0.015612   \n",
       "58506   -0.111281   -0.111323     2.29070     2.29070     2.28960    0.007406   \n",
       "58507   -0.111281   -0.111323     2.29050     2.29040     2.28980    0.019670   \n",
       "58508   -0.111281   -0.111323     2.29300     2.29290     2.29220    0.029245   \n",
       "\n",
       "       current_28  current_33  current_34  current_35  current_37  current_44  \n",
       "0        0.004879   -0.001248   -0.004378   -0.004384    -0.66732     -1.4961  \n",
       "1        0.007111    0.001068   -0.001344   -0.001342    -0.65404     -1.4967  \n",
       "2        0.000445    0.002885    0.000350    0.000358    -0.67146     -1.4983  \n",
       "3        0.006936   -0.001277   -0.004974   -0.004966    -0.67766     -1.4963  \n",
       "4        0.005616   -0.003800   -0.004655   -0.004646    -0.65867     -1.4958  \n",
       "...           ...         ...         ...         ...         ...         ...  \n",
       "58504    0.004317   -0.008362    0.001726    0.001733    -0.41812     -1.5025  \n",
       "58505    0.007677   -0.009709   -0.000064    0.000033    -0.42137     -1.5025  \n",
       "58506    0.008709   -0.008109    0.000646    0.000523    -0.39929     -1.5035  \n",
       "58507    0.003671   -0.010470   -0.000125   -0.000153    -0.43276     -1.5029  \n",
       "58508   -0.010920   -0.010627   -0.001158   -0.001167    -0.43513     -1.5040  \n",
       "\n",
       "[58509 rows x 17 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[selected_features] \n",
    "y = df['output']\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb022352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "58504    11\n",
       "58505    11\n",
       "58506    11\n",
       "58507    11\n",
       "58508    11\n",
       "Name: output, Length: 58509, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d33f9",
   "metadata": {},
   "source": [
    "### Now using the best model from Part 2 with the above selected variables. Here, we got Random Forests as the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1fca42e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_4</th>\n",
       "      <th>current_5</th>\n",
       "      <th>current_7</th>\n",
       "      <th>current_8</th>\n",
       "      <th>current_10</th>\n",
       "      <th>current_12</th>\n",
       "      <th>current_19</th>\n",
       "      <th>current_20</th>\n",
       "      <th>current_21</th>\n",
       "      <th>current_25</th>\n",
       "      <th>current_28</th>\n",
       "      <th>current_33</th>\n",
       "      <th>current_34</th>\n",
       "      <th>current_35</th>\n",
       "      <th>current_37</th>\n",
       "      <th>current_44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11040</th>\n",
       "      <td>4.852900e-06</td>\n",
       "      <td>-4.779300e-06</td>\n",
       "      <td>2.542500e-06</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>1.2888</td>\n",
       "      <td>1.28880</td>\n",
       "      <td>1.28880</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>-0.58624</td>\n",
       "      <td>-1.4968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289</th>\n",
       "      <td>-8.251500e-06</td>\n",
       "      <td>-8.923300e-07</td>\n",
       "      <td>-4.367600e-06</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>0.021589</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>1.7031</td>\n",
       "      <td>1.70310</td>\n",
       "      <td>1.70310</td>\n",
       "      <td>-0.003381</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>-0.001286</td>\n",
       "      <td>-0.51465</td>\n",
       "      <td>-1.4986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35768</th>\n",
       "      <td>3.467800e-05</td>\n",
       "      <td>4.093600e-07</td>\n",
       "      <td>5.364300e-06</td>\n",
       "      <td>0.036610</td>\n",
       "      <td>0.036575</td>\n",
       "      <td>0.099751</td>\n",
       "      <td>0.099757</td>\n",
       "      <td>1.7128</td>\n",
       "      <td>1.71270</td>\n",
       "      <td>1.71200</td>\n",
       "      <td>-0.015251</td>\n",
       "      <td>-0.026370</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.019165</td>\n",
       "      <td>-0.63484</td>\n",
       "      <td>-1.5085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-4.811100e-06</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>-0.030159</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.89481</td>\n",
       "      <td>0.89479</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>-0.004974</td>\n",
       "      <td>-0.004966</td>\n",
       "      <td>-0.67766</td>\n",
       "      <td>-1.4963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>-9.204200e-07</td>\n",
       "      <td>-7.352800e-06</td>\n",
       "      <td>3.407100e-06</td>\n",
       "      <td>-0.028637</td>\n",
       "      <td>-0.028636</td>\n",
       "      <td>-0.036603</td>\n",
       "      <td>-0.036589</td>\n",
       "      <td>1.0765</td>\n",
       "      <td>1.07650</td>\n",
       "      <td>1.07640</td>\n",
       "      <td>0.009385</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>-0.58003</td>\n",
       "      <td>-1.4982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54343</th>\n",
       "      <td>-5.532400e-06</td>\n",
       "      <td>-3.484000e-08</td>\n",
       "      <td>-3.860900e-06</td>\n",
       "      <td>-0.071745</td>\n",
       "      <td>-0.071739</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>-0.111323</td>\n",
       "      <td>1.2198</td>\n",
       "      <td>1.21980</td>\n",
       "      <td>1.21950</td>\n",
       "      <td>0.012522</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>-0.011233</td>\n",
       "      <td>-0.017635</td>\n",
       "      <td>-0.017641</td>\n",
       "      <td>-0.72497</td>\n",
       "      <td>-1.4974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>1.568000e-06</td>\n",
       "      <td>6.281500e-07</td>\n",
       "      <td>1.255600e-06</td>\n",
       "      <td>0.042352</td>\n",
       "      <td>0.042350</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.023703</td>\n",
       "      <td>1.8583</td>\n",
       "      <td>1.85830</td>\n",
       "      <td>1.85830</td>\n",
       "      <td>-0.003804</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>-0.47078</td>\n",
       "      <td>-1.4974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>6.599000e-06</td>\n",
       "      <td>-9.159900e-07</td>\n",
       "      <td>-1.304700e-06</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.025895</td>\n",
       "      <td>-0.040507</td>\n",
       "      <td>-0.040514</td>\n",
       "      <td>1.3382</td>\n",
       "      <td>1.33820</td>\n",
       "      <td>1.33820</td>\n",
       "      <td>0.012896</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>-0.002088</td>\n",
       "      <td>-0.002087</td>\n",
       "      <td>-0.54689</td>\n",
       "      <td>-1.4991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>-6.427550e-05</td>\n",
       "      <td>5.818100e-06</td>\n",
       "      <td>3.163500e-05</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>-0.003350</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>2.1107</td>\n",
       "      <td>2.11060</td>\n",
       "      <td>2.10960</td>\n",
       "      <td>-0.028799</td>\n",
       "      <td>-0.026895</td>\n",
       "      <td>-0.003007</td>\n",
       "      <td>0.017799</td>\n",
       "      <td>0.017777</td>\n",
       "      <td>-0.54712</td>\n",
       "      <td>-1.5038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56422</th>\n",
       "      <td>-2.880500e-05</td>\n",
       "      <td>-1.887580e-05</td>\n",
       "      <td>-5.429700e-05</td>\n",
       "      <td>-0.086972</td>\n",
       "      <td>-0.087041</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>-0.111323</td>\n",
       "      <td>1.3753</td>\n",
       "      <td>1.37540</td>\n",
       "      <td>1.37460</td>\n",
       "      <td>0.021965</td>\n",
       "      <td>0.035522</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>-0.015693</td>\n",
       "      <td>-0.015641</td>\n",
       "      <td>-0.70844</td>\n",
       "      <td>-1.4969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29254 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          current_2     current_4     current_5  current_7  current_8  \\\n",
       "11040  4.852900e-06 -4.779300e-06  2.542500e-06   0.003926   0.003921   \n",
       "11289 -8.251500e-06 -8.923300e-07 -4.367600e-06   0.012692   0.012701   \n",
       "35768  3.467800e-05  4.093600e-07  5.364300e-06   0.036610   0.036575   \n",
       "3      8.820100e-06 -4.811100e-06 -7.282900e-07   0.029410   0.029401   \n",
       "5599  -9.204200e-07 -7.352800e-06  3.407100e-06  -0.028637  -0.028636   \n",
       "...             ...           ...           ...        ...        ...   \n",
       "54343 -5.532400e-06 -3.484000e-08 -3.860900e-06  -0.071745  -0.071739   \n",
       "38158  1.568000e-06  6.281500e-07  1.255600e-06   0.042352   0.042350   \n",
       "860    6.599000e-06 -9.159900e-07 -1.304700e-06   0.025901   0.025895   \n",
       "15795 -6.427550e-05  5.818100e-06  3.163500e-05  -0.003429  -0.003350   \n",
       "56422 -2.880500e-05 -1.887580e-05 -5.429700e-05  -0.086972  -0.087041   \n",
       "\n",
       "       current_10  current_12  current_19  current_20  current_21  current_25  \\\n",
       "11040    0.001160    0.001170      1.2888     1.28880     1.28880    0.001646   \n",
       "11289    0.021589    0.021610      1.7031     1.70310     1.70310   -0.003381   \n",
       "35768    0.099751    0.099757      1.7128     1.71270     1.71200   -0.015251   \n",
       "3       -0.030156   -0.030159      0.8948     0.89481     0.89479    0.002056   \n",
       "5599    -0.036603   -0.036589      1.0765     1.07650     1.07640    0.009385   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "54343   -0.111281   -0.111323      1.2198     1.21980     1.21950    0.012522   \n",
       "38158    0.023688    0.023703      1.8583     1.85830     1.85830   -0.003804   \n",
       "860     -0.040507   -0.040514      1.3382     1.33820     1.33820    0.012896   \n",
       "15795    0.020371    0.019904      2.1107     2.11060     2.10960   -0.028799   \n",
       "56422   -0.111281   -0.111323      1.3753     1.37540     1.37460    0.021965   \n",
       "\n",
       "       current_28  current_33  current_34  current_35  current_37  current_44  \n",
       "11040    0.010940    0.000452   -0.000847   -0.000851    -0.58624     -1.4968  \n",
       "11289   -0.001123   -0.000034   -0.001289   -0.001286    -0.51465     -1.4986  \n",
       "35768   -0.026370    0.000478    0.019182    0.019165    -0.63484     -1.5085  \n",
       "3        0.006936   -0.001277   -0.004974   -0.004966    -0.67766     -1.4963  \n",
       "5599     0.012049   -0.006667    0.003245    0.003252    -0.58003     -1.4982  \n",
       "...           ...         ...         ...         ...         ...         ...  \n",
       "54343    0.003452   -0.011233   -0.017635   -0.017641    -0.72497     -1.4974  \n",
       "38158   -0.000300    0.004420    0.000084    0.000078    -0.47078     -1.4974  \n",
       "860      0.003724    0.000482   -0.002088   -0.002087    -0.54689     -1.4991  \n",
       "15795   -0.026895   -0.003007    0.017799    0.017777    -0.54712     -1.5038  \n",
       "56422    0.035522    0.020597   -0.015693   -0.015641    -0.70844     -1.4969  \n",
       "\n",
       "[29254 rows x 17 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dividing the dataset into train,test and validation sets\n",
    "X_train, X_rem, y_train, y_rem  = train_test_split(X, y, train_size = 0.5, random_state = 42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size = 0.5, random_state = 42)\n",
    "\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e1c25b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The input training  data shape is (29254, 17)\n",
      " The  output training data shape is (29254,)\n"
     ]
    }
   ],
   "source": [
    "# The shape of training dataset\n",
    "print(f\" The input training  data shape is {X_train.shape}\")\n",
    "print(f\" The  output training data shape is {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7a10ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The input training  data shape is (14627, 17)\n",
      " The  output training data shape is (14627,)\n"
     ]
    }
   ],
   "source": [
    "# The shape of validation dataset\n",
    "print(f\" The input training  data shape is {X_valid.shape}\")\n",
    "print(f\" The  output training data shape is {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3bf3396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The input training  data shape is (14627, 17)\n",
      " The  output training data shape is (14627,)\n"
     ]
    }
   ],
   "source": [
    "# The shape of the test dataset \n",
    "print(f\" The input training  data shape is {X_valid.shape}\")\n",
    "print(f\" The  output training data shape is {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1bc17c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting a random model \n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8aa0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random model training score is 1.0\n",
      " Random model validation data score is 0.9966500307650236\n",
      " Random model testing score is 0.9972655181843041\n"
     ]
    }
   ],
   "source": [
    "# accuracy scores on the three datasets\n",
    "print(f\" Random model training score is {model_rf.score(X_train,y_train)}\")\n",
    "print(f\" Random model validation data score is {model_rf.score(X_valid,y_valid)}\")\n",
    "print(f\" Random model testing score is {model_rf.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae4cb713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      1343\n",
      "           2       0.99      1.00      1.00      1336\n",
      "           3       1.00      0.99      1.00      1303\n",
      "           4       1.00      1.00      1.00      1303\n",
      "           5       0.99      1.00      0.99      1295\n",
      "           6       1.00      1.00      1.00      1335\n",
      "           7       1.00      1.00      1.00      1396\n",
      "           8       0.99      1.00      1.00      1331\n",
      "           9       0.99      1.00      1.00      1311\n",
      "          10       1.00      0.99      0.99      1316\n",
      "          11       1.00      1.00      1.00      1358\n",
      "\n",
      "    accuracy                           1.00     14627\n",
      "   macro avg       1.00      1.00      1.00     14627\n",
      "weighted avg       1.00      1.00      1.00     14627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for validation dataset\n",
    "y_pred_va = model_rf.predict(X_valid)\n",
    "print(classification_report(y_pred_va,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3713e8e3",
   "metadata": {},
   "source": [
    "### Finding the best model using Hyperparameter validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37c1c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e7a7e328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [5, 10], 'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [50, 100]})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Grid Search CV object and fit it to the Validation data\n",
    "grid_search = GridSearchCV(model_rf, param_grid, cv=5)\n",
    "grid_search.fit(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e2c5c9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd36ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best classification tree for the above data\n",
    "best_rf = RandomForestClassifier(max_depth = 10, min_samples_leaf= 1, min_samples_split= 5, n_estimators= 50)\n",
    "best_rf.fit(X_train,y_train)\n",
    "filename = 'RF_class.sav'\n",
    "pickle.dump(best_rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49d6e3",
   "metadata": {},
   "source": [
    "### Accuracy of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c9e702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training data accuracy for the best model is 0.9910097764408285\n",
      " The validation data accuracy for the best model is 0.9863266561837697\n",
      " The testing data accuracy for the best model is 0.9867377631938747\n"
     ]
    }
   ],
   "source": [
    "# Best model training \n",
    "best_rf.fit(X_train,y_train)\n",
    "# Accuracy scores of best tree on different datasets\n",
    "y_train_pred = best_rf.predict(X_train)\n",
    "print(f\" The training data accuracy for the best model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "y_valid_pred = best_rf.predict(X_valid) \n",
    "print(f\" The validation data accuracy for the best model is {accuracy_score(y_valid,y_valid_pred)}\")\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "print(f\" The testing data accuracy for the best model is {accuracy_score(y_test,y_test_pred)}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee04d3",
   "metadata": {},
   "source": [
    "### Confusion matrices for Training data, Validation data and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ab808336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2623    0    0    0    0   20    0    0    0    0    0]\n",
      " [   0 2593    0    0    0    1    0    0    8   21    0]\n",
      " [   0    0 2653    0   31    0    0    0    1    0    0]\n",
      " [   0    0   18 2655    6    0    0    0    0    0    0]\n",
      " [   0    0   21    3 2660    0    0   32    0    0    0]\n",
      " [   8    0    0    0    0 2602    0    0   16    0    0]\n",
      " [   0    0    0    0    0    0 2609    0    0    0    0]\n",
      " [   0    0    0    8   33    0    0 2624    0    0    0]\n",
      " [   8    1    0    0    1   25    0    0 2658    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0 2662    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 2652]]\n"
     ]
    }
   ],
   "source": [
    "### Training Data\n",
    "print(confusion_matrix(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4dabe48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1333    0    0    0    0   11    0    0    1    0    0]\n",
      " [   0 1309    0    0    0    1    0    0    7   21    1]\n",
      " [   0    0 1276    0   17    0    0    0    0    0    0]\n",
      " [   0    0    8 1282    9    0    0    0    0    0    0]\n",
      " [   0    0   19    1 1263    0    0   22    0    0    0]\n",
      " [   7    0    0    0    0 1318    0    0   11    0    1]\n",
      " [   0    0    0    0    0    0 1396    0    0    0    0]\n",
      " [   0    0    0    9   25    0    0 1301    0    0    0]\n",
      " [   0    3    0    0    0   14    0    0 1293    4    0]\n",
      " [   0    6    0    0    0    1    0    0    1 1300    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1356]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for validation data\n",
    "print(confusion_matrix(y_valid,y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c2aacdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1315    0    0    0    0   12    0    0    4    0    0]\n",
      " [   0 1336    1    0    0    2    0    0    4   13    1]\n",
      " [   0    0 1315    0   26    0    0    0    0    0    0]\n",
      " [   0    0    3 1333    5    0    0    0    0    0    0]\n",
      " [   0    0   15    3 1260    0    0   20    0    0    0]\n",
      " [  14    0    0    0    0 1332    0    0   10    0    0]\n",
      " [   0    0    0    0    0    0 1314    0    0    0    0]\n",
      " [   0    1    0    8   20    0    0 1290    0    0    0]\n",
      " [   3    3    1    0    0   16    0    1 1286    2    0]\n",
      " [   0    6    0    0    0    0    0    0    0 1342    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1311]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for testing data\n",
    "print(confusion_matrix(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8dfdc",
   "metadata": {},
   "source": [
    "### Classification Report for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6f458b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99      2643\n",
      "           2       1.00      0.99      0.99      2623\n",
      "           3       0.99      0.99      0.99      2685\n",
      "           4       1.00      0.99      0.99      2679\n",
      "           5       0.97      0.98      0.98      2716\n",
      "           6       0.98      0.99      0.99      2626\n",
      "           7       1.00      1.00      1.00      2609\n",
      "           8       0.99      0.98      0.99      2665\n",
      "           9       0.99      0.99      0.99      2693\n",
      "          10       0.99      1.00      1.00      2663\n",
      "          11       1.00      1.00      1.00      2652\n",
      "\n",
      "    accuracy                           0.99     29254\n",
      "   macro avg       0.99      0.99      0.99     29254\n",
      "weighted avg       0.99      0.99      0.99     29254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the training data\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1f1bbca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99      1331\n",
      "           2       0.99      0.98      0.99      1357\n",
      "           3       0.99      0.98      0.98      1341\n",
      "           4       0.99      0.99      0.99      1341\n",
      "           5       0.96      0.97      0.97      1298\n",
      "           6       0.98      0.98      0.98      1356\n",
      "           7       1.00      1.00      1.00      1314\n",
      "           8       0.98      0.98      0.98      1319\n",
      "           9       0.99      0.98      0.98      1312\n",
      "          10       0.99      1.00      0.99      1348\n",
      "          11       1.00      1.00      1.00      1311\n",
      "\n",
      "    accuracy                           0.99     14628\n",
      "   macro avg       0.99      0.99      0.99     14628\n",
      "weighted avg       0.99      0.99      0.99     14628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for the testing data\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cc1a5086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99      1345\n",
      "           2       0.99      0.98      0.99      1339\n",
      "           3       0.98      0.99      0.98      1293\n",
      "           4       0.99      0.99      0.99      1299\n",
      "           5       0.96      0.97      0.96      1305\n",
      "           6       0.98      0.99      0.98      1337\n",
      "           7       1.00      1.00      1.00      1396\n",
      "           8       0.98      0.97      0.98      1335\n",
      "           9       0.98      0.98      0.98      1314\n",
      "          10       0.98      0.99      0.99      1308\n",
      "          11       1.00      1.00      1.00      1356\n",
      "\n",
      "    accuracy                           0.99     14627\n",
      "   macro avg       0.99      0.99      0.99     14627\n",
      "weighted avg       0.99      0.99      0.99     14627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for the validation data\n",
    "print(classification_report(y_valid,y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad342849",
   "metadata": {},
   "source": [
    "### ROC_AUC score of the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "017ad3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The roc_auc score for the training data is 0.9999219377376288\n",
      " The roc_auc score for the validation data is 0.9998211425220086\n",
      " The roc_auc score for the testing data is 0.9997014510862904\n"
     ]
    }
   ],
   "source": [
    "# roc auc score for training data\n",
    "y_train_prob = best_rf.predict_proba(X_train)\n",
    "print(f\" The roc_auc score for the training data is {roc_auc_score(y_train,y_train_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the validation data\n",
    "y_valid_prob = best_rf.predict_proba(X_valid)\n",
    "print(f\" The roc_auc score for the validation data is {roc_auc_score(y_valid,y_valid_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the testing data\n",
    "y_test_prob = best_rf.predict_proba(X_test)\n",
    "print(f\" The roc_auc score for the testing data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f912c8",
   "metadata": {},
   "source": [
    "### Recall score of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ccad7eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The recall score for the training data is 0.9910549276431125\n",
      " The recall score for the validation data is 0.9862252402573422\n",
      " The recall score for the testing data is 0.9867200043359645\n"
     ]
    }
   ],
   "source": [
    "# recall score for training data\n",
    "print(f\" The recall score for the training data is {recall_score(y_train,y_train_pred,average= 'macro')}\")\n",
    "# recall score for validation data\n",
    "print(f\" The recall score for the validation data is {recall_score(y_valid,y_valid_pred,average= 'macro')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the testing data is {recall_score(y_test,y_test_pred,average= 'macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbbd1b2",
   "metadata": {},
   "source": [
    "### F1 score of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64ae6b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The f-1 score for the training data is 0.9910148575471823\n",
      " The f-1 score for the validation data is 0.9863319830180551\n",
      " The f-1 score for the testing data is 0.9867429108628423\n"
     ]
    }
   ],
   "source": [
    "# F-1 score for training data\n",
    "print(f\" The f-1 score for the training data is {f1_score(y_train,y_train_pred,average= 'weighted')}\")\n",
    "# F-1 score for validation data\n",
    "print(f\" The f-1 score for the validation data is {f1_score(y_valid,y_valid_pred,average= 'weighted')}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the testing data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ea9cb",
   "metadata": {},
   "source": [
    "### Now using the best model from Part 3 with the above selected variables. Here, we got Multi Layer Perceptron (Deep Learning Model) as the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1b2b9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54585804 0.46159247 0.47343561 ... 0.37853362 0.46237036 0.72596154]\n",
      " [0.44420547 0.35720615 0.50461629 ... 0.45881715 0.48743477 0.69711538]\n",
      " [0.45973556 0.49228171 0.47242496 ... 0.50367823 0.45455661 0.62019231]\n",
      " ...\n",
      " [0.62362286 0.42903357 0.51236877 ... 0.50802255 0.96824483 0.37019231]\n",
      " [0.73932528 0.66981342 0.53213293 ... 0.49019982 0.90507422 0.39903846]\n",
      " [0.87696412 0.80365741 0.51213293 ... 0.46341956 0.90060113 0.34615385]]\n"
     ]
    }
   ],
   "source": [
    "# Importing the deep learning model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Scaling is very important in the case of linear regression\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "print(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "84ce95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset into train,test and validation sets\n",
    "X_train, X_rem, y_train, y_rem  = train_test_split(scaled_X, y, train_size = 0.5, random_state = 100)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size = 0.5, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd1aa9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohith Varma\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking MLP model\n",
    "mlp = MLPClassifier()\n",
    "#fitting MLP model with training data\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "145f2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Predictions for the MLP model\n",
    "y_train_pred_mlp = mlp.predict(X_train)\n",
    "y_valid_pred_mlp = mlp.predict(X_valid)\n",
    "y_test_pred_mlp  = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9ebbd47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training data accuracy for the best model is 0.9819853695221167\n",
      " The validation data accuracy for the best model is 0.9779175497367881\n",
      " The testing data accuracy for the best model is 0.9767569045665846\n"
     ]
    }
   ],
   "source": [
    "#Printing the accuracies for the MLP model\n",
    "print(f\" The training data accuracy for the best model is {accuracy_score(y_train,y_train_pred_mlp)}\")\n",
    "print(f\" The validation data accuracy for the best model is {accuracy_score(y_valid,y_valid_pred_mlp)}\")\n",
    "print(f\" The testing data accuracy for the best model is {accuracy_score(y_test,y_test_pred_mlp)}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f89429b",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning for the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "mlp = MLPClassifier()\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (200,), (500,), (1000,)],\n",
    "    'activation': ['relu', 'logistic'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "\n",
    "clf = RandomizedSearchCV(mlp, param_grid, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dbc97898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50,), 'alpha': 0.001, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print(f'Best hyperparameters: {clf.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "088eeb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohith Varma\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, hidden_layer_sizes=(500,), learning_rate='adaptive')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model \n",
    "best_model_mlp =  MLPClassifier(solver= 'adam', learning_rate= 'adaptive', hidden_layer_sizes= (500,), alpha= 0.001, activation= 'relu')\n",
    "best_model_mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce799815",
   "metadata": {},
   "source": [
    "### Accuracies for Training, Testing and Validation Datasets for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "426eb3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training data accuracy for the best model is 0.9943255623162645\n",
      " The validation data accuracy for the best model is 0.9903602926095577\n",
      " The testing data accuracy for the best model is 0.988651900464862\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_best_mlp = best_model_mlp.predict(X_train)\n",
    "y_valid_pred_best_mlp = best_model_mlp.predict(X_valid)\n",
    "y_test_pred_best_mlp  = best_model_mlp.predict(X_test)\n",
    "print(f\" The training data accuracy for the best model is {accuracy_score(y_train,y_train_pred_best_mlp)}\")\n",
    "print(f\" The validation data accuracy for the best model is {accuracy_score(y_valid,y_valid_pred_best_mlp)}\")\n",
    "print(f\" The testing data accuracy for the best model is {accuracy_score(y_test,y_test_pred_best_mlp)}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230c287",
   "metadata": {},
   "source": [
    "### Confusion Matrices for Training, Testing and Validation Datasets for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "553a69e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2665    0    0    0    0   19    0    0    0    0    0]\n",
      " [   0 2551    0    0    0    0    0    0    1   11    0]\n",
      " [   0    0 2737    0    2    0    0    0    0    0    0]\n",
      " [   0    0    2 2686    0    0    0    0    0    0    0]\n",
      " [   0    0   19    2 2669    0    0   25    0    1    0]\n",
      " [  16    0    0    0    0 2585    0    1    6    0    0]\n",
      " [   0    0    0    0    0    0 2686    0    0    0    0]\n",
      " [   0    0    0    2   18    1    0 2634    0    1    0]\n",
      " [   3    1    0    0    0   12    0    1 2681    1    0]\n",
      " [   0   21    0    0    0    0    0    0    0 2596    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 2598]]\n"
     ]
    }
   ],
   "source": [
    "### Training Data\n",
    "print(confusion_matrix(y_train,y_train_pred_best_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bd410641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1320    0    0    0    0   12    0    0    0    0    0]\n",
      " [   0 1377    0    1    0    0    0    0    0   11    0]\n",
      " [   0    0 1286    0    3    0    0    0    1    0    0]\n",
      " [   0    0    0 1335    0    0    0    0    0    1    0]\n",
      " [   0    0    9    0 1280    0    0   13    0    0    0]\n",
      " [   8    0    0    0    0 1319    0    0   13    0    0]\n",
      " [   0    0    0    2    0    0 1303    0    0    0    0]\n",
      " [   1    0    0    4   16    0    0 1298    0    0    0]\n",
      " [   1    1    2    0    0    7    0    0 1314    0    0]\n",
      " [   0   35    0    0    0    0    0    0    0 1308    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1346]]\n"
     ]
    }
   ],
   "source": [
    "### validation Data\n",
    "print(confusion_matrix(y_valid,y_valid_pred_best_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e519c832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1295    0    0    0    0    7    0    0    1    0    0]\n",
      " [   0 1351    0    0    0    0    0    0    0   15    1]\n",
      " [   0    0 1285    0    4    1    0    0    0    0    0]\n",
      " [   0    0    3 1291    0    0    0    1    0    0    0]\n",
      " [   0    0    7    2 1271    0    0   21    0    0    0]\n",
      " [  12    0    1    0    0 1347    0    0   11    0    0]\n",
      " [   0    0    0    0    0    0 1328    0    0    0    0]\n",
      " [   0    0    0    1   21    0    0 1320    2    0    0]\n",
      " [   2    1    5    0    0   15    0    0 1272    0    0]\n",
      " [   0   31    0    0    0    0    0    0    1 1327    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1375]]\n"
     ]
    }
   ],
   "source": [
    "### Testing Data\n",
    "print(confusion_matrix(y_test,y_test_pred_best_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e2a3f",
   "metadata": {},
   "source": [
    "### Classification Reports for Training, Testing and Validation Datasets for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "df015982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99      2684\n",
      "           2       0.99      1.00      0.99      2563\n",
      "           3       0.99      1.00      1.00      2739\n",
      "           4       1.00      1.00      1.00      2688\n",
      "           5       0.99      0.98      0.99      2716\n",
      "           6       0.99      0.99      0.99      2608\n",
      "           7       1.00      1.00      1.00      2686\n",
      "           8       0.99      0.99      0.99      2656\n",
      "           9       1.00      0.99      1.00      2699\n",
      "          10       0.99      0.99      0.99      2617\n",
      "          11       1.00      1.00      1.00      2598\n",
      "\n",
      "    accuracy                           0.99     29254\n",
      "   macro avg       0.99      0.99      0.99     29254\n",
      "weighted avg       0.99      0.99      0.99     29254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the training data\n",
    "print(classification_report(y_train,y_train_pred_best_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "321c9b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99      1332\n",
      "           2       0.97      0.99      0.98      1389\n",
      "           3       0.99      1.00      0.99      1290\n",
      "           4       0.99      1.00      1.00      1336\n",
      "           5       0.99      0.98      0.98      1302\n",
      "           6       0.99      0.98      0.99      1340\n",
      "           7       1.00      1.00      1.00      1305\n",
      "           8       0.99      0.98      0.99      1319\n",
      "           9       0.99      0.99      0.99      1325\n",
      "          10       0.99      0.97      0.98      1343\n",
      "          11       1.00      1.00      1.00      1346\n",
      "\n",
      "    accuracy                           0.99     14627\n",
      "   macro avg       0.99      0.99      0.99     14627\n",
      "weighted avg       0.99      0.99      0.99     14627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the validation data\n",
    "print(classification_report(y_valid,y_valid_pred_best_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bb65123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99      1303\n",
      "           2       0.98      0.99      0.98      1367\n",
      "           3       0.99      1.00      0.99      1290\n",
      "           4       1.00      1.00      1.00      1295\n",
      "           5       0.98      0.98      0.98      1301\n",
      "           6       0.98      0.98      0.98      1371\n",
      "           7       1.00      1.00      1.00      1328\n",
      "           8       0.98      0.98      0.98      1344\n",
      "           9       0.99      0.98      0.99      1295\n",
      "          10       0.99      0.98      0.98      1359\n",
      "          11       1.00      1.00      1.00      1375\n",
      "\n",
      "    accuracy                           0.99     14628\n",
      "   macro avg       0.99      0.99      0.99     14628\n",
      "weighted avg       0.99      0.99      0.99     14628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the testing data\n",
    "print(classification_report(y_test,y_test_pred_best_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55a8c6",
   "metadata": {},
   "source": [
    "### ROC_auc_score for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9e7da562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The roc_auc score for the training data is 0.999922176856319\n",
      " The roc_auc score for the validation data is 0.9998080774452239\n",
      " The roc_auc score for the testing data is 0.9998215175585333\n"
     ]
    }
   ],
   "source": [
    "# roc auc score for training data\n",
    "y_train_prob = best_model_mlp.predict_proba(X_train)\n",
    "print(f\" The roc_auc score for the training data is {roc_auc_score(y_train,y_train_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the validation data\n",
    "y_valid_prob = best_model_mlp.predict_proba(X_valid)\n",
    "print(f\" The roc_auc score for the validation data is {roc_auc_score(y_valid,y_valid_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the testing data\n",
    "y_test_prob = best_model_mlp.predict_proba(X_test)\n",
    "print(f\" The roc_auc score for the testing data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163fd53b",
   "metadata": {},
   "source": [
    "### Recall score for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3ddd727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The recall score for the training data is 0.9943331050729739\n",
      " The recall score for the validation data is 0.9903742742889886\n",
      " The recall score for the testing data is 0.9886783587338985\n"
     ]
    }
   ],
   "source": [
    "# recall score for training data\n",
    "print(f\" The recall score for the training data is {recall_score(y_train,y_train_pred_best_mlp,average= 'macro')}\")\n",
    "# recall score for validation data\n",
    "print(f\" The recall score for the validation data is {recall_score(y_valid,y_valid_pred_best_mlp,average= 'macro')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the testing data is {recall_score(y_test,y_test_pred_best_mlp,average= 'macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b031a",
   "metadata": {},
   "source": [
    "### F1-score for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "196974cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The f-1 score for the training data is 0.9943231033896528\n",
      " The f-1 score for the validation data is 0.9903566464668352\n",
      " The f-1 score for the testing data is 0.9886466290187369\n"
     ]
    }
   ],
   "source": [
    "# F-1 score for training data\n",
    "print(f\" The f-1 score for the training data is {f1_score(y_train,y_train_pred_best_mlp,average= 'weighted')}\")\n",
    "# F-1 score for validation data\n",
    "print(f\" The f-1 score for the validation data is {f1_score(y_valid,y_valid_pred_best_mlp,average= 'weighted')}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the testing data is {f1_score(y_test,y_test_pred_best_mlp,average= 'weighted')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
